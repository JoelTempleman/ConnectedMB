{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex, HTML\n",
    "HTML('''<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "  \n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>''') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConnectIN draft analysis, part 3 - Feb 07, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document contains:\n",
    "- information about bandwith purchased (possibly outdated), added to the upload/download speed data.\n",
    "- observations for data coming from the `iperf` testing tool (download/upload speeds, ping latency)  and comparing this data to the data coming from the `speedtest` platform.\n",
    "- statistical analysis of the download speed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries:\n",
    "from data_exploration import *\n",
    "#for plotly distribution plots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from data_statistics import *\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up influxdb connection:\n",
    "client, client_df = connect_to_influxdb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bandwidth purchased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the initial analysis of speedtest data, one aspect that remained unclear is how much bandwidth each organization hosting a device is purchasing. The amount being purchased would set an upper limit to the bandwidth throughput we would expect to see. Another complicating factor in this equation is that it is not known how much bandwidth is available to each organization. For example, if organization A purchases 10 Mbps, why are they not buying 50 or 100? It could be by choice or alternatively because those speeds are not available or too expensive. \n",
    "\n",
    "The data shown here is approximately one year old and as such, might be outdated. It will be added to the download/upload speeds graphs.  The graphs will display 4 weeks of data coming from `speedtest` back from the meeting date: `Feb 07, 2019, 14:00` on which the results were presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=False\n",
    "#Collect all data?\n",
    "#all_data=True\n",
    "\n",
    "#Set up test time interval:\n",
    "time_interval='4w' #2w\n",
    "\n",
    "#Set up starting point, by default if will start from current time\n",
    "#starting_point=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "starting_point=\"2019-01-07 14:00:00\"  # to set upl alternative starting point\n",
    "\n",
    "title_tail=\"\"\n",
    "query_tail=\"\"\n",
    "\n",
    "if not all_data:\n",
    "    ##tail to all the titles\n",
    "    title_tail=\" over the last \"+time_interval+ \" back  from \"+ starting_point\n",
    "    ##tail for all the influxdb queries\n",
    "    query_tail=\" AND time >= '\"+starting_point+\"'-\"+time_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Matching coordinates from given mac addresses to device numbers from MS SQL table\n",
    "coordinates_df = pd.read_csv(\"../coordinates2.csv\")\n",
    "#cnxn = connect_to_mssql()\n",
    "#sql = \"SELECT DISTINCT PI_MAC, PK_PI FROM  DIM_PI;\"\n",
    "#df_frommssql=pd.read_sql(sql,cnxn)\n",
    "#coordinates_df=pd.merge(coordinates_df, df_frommssql,  how='left', left_on=['mac'], right_on = ['PI_MAC'])\n",
    "#coordinates_df.rename(columns={'PK_PI':'device_number'}, inplace=True)\n",
    "#coordinates_df = coordinates_df[[\"lat\",\"lon\",\"name\",\"mac\",\"device_number\",\"Up\",\"Down\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table: Location names with device numbers and known bandwidth purchased amounts\")\n",
    "coordinates_df[[\"name\",\"device_number\"]]#,\"Up\",\"Down\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_download = \"SELECT * FROM SPEEDTEST_IPERF_DOWNLOAD WHERE PROVIDER!='iperf' AND DOWNLOAD>0\"+ query_tail+\";\"\n",
    "download_df = get_dataframe_from_influxdb(client_df=client_df,query_influx=query_download,table_name='SPEEDTEST_IPERF_DOWNLOAD')\n",
    "download_df=download_df[download_df[\"SK_PI\"]!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_numbers_d=download_df['SK_PI'].unique()\n",
    "device_numbers_d=list(map(int, device_numbers_d))\n",
    "device_numbers_d= sorted(device_numbers_d)\n",
    "download_df[\"hour\"]=pd.to_numeric(download_df[\"time\"].dt.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_subset_d=coordinates_df[coordinates_df[\"device_number\"].isin(device_numbers_d)]\n",
    "#coordinates_subset_d=coordinates_subset_d[np.isfinite(coordinates_subset_d['Down'])]\n",
    "coordinates_subset_d=coordinates_subset_d.sort_values(by=\"device_number\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_line=go.Scatter(x=coordinates_subset_d[\"device_number\"],y=coordinates_subset_d[\"Down\"], mode='markers',marker=dict(color='blue'), name='Bandwidth bought')\n",
    "\n",
    "t=\"Bandwidth bought and download speeds\"+title_tail                                                      \n",
    "simple_boxplot(dataframe=download_df,plot_value='DOWNLOAD',sort_value='SK_PI',\n",
    "               title=t, \n",
    "               ytitle=\"Download speed (Mbps)\",\n",
    "               xtitle=\"Device number\", downloadline=True)#,boughtline=b_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot above, it is possible that for devices 10, 12, and 16, the bandwidth purchased amount is correct as all the datapoints are at or below the purchased amount. For the rest of the devices the \"bandwith bought\" dot is significantly lower than the measured speeds, which likely indicates that this bandwidth purchased data is incorrect. \n",
    "\n",
    "Below, the plot shows the bandwidth purchased compared to the measured upload speeds. In this case, only device 10 sees the data fall at or below the bandwidth purchased. For device 16, which looked correct for Download speeds, the bandwidth purchased amount is 0.496 Mbps but on the graph we see speeds below 4Mbps, raising questions about the data's accuracy. \n",
    "\n",
    "These observations raise important questions about how the speedtest data can be interpreted. Without knowing how much bandwidth is purchased at each device, it is difficult to ascertain whether it would be possible to meet CRTC targets in those locations or whether these locations should be considered served and underserved. Furthermore, in cases where less bandwidth is purchased at levels lower than the CRTC targets, the question remains whether this is because a) higher speeds are not available, b) organizations choose not to buy more data or c) if it is cost-prohibitive. As such, collecting this contextual information will be important going forward in order to be able to ensure the data is interpreted correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_upload = \"SELECT * FROM SPEEDTEST_IPERF_UPLOAD WHERE PROVIDER!='iperf' AND UPLOAD>0\"+ query_tail+\";\"\n",
    "upload_df = get_dataframe_from_influxdb(client_df=client_df,query_influx=query_upload,table_name='SPEEDTEST_IPERF_UPLOAD')\n",
    "upload_df=upload_df[upload_df[\"SK_PI\"]!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_numbers_u=upload_df['SK_PI'].unique()\n",
    "device_numbers_u=list(map(int, device_numbers_u))\n",
    "device_numbers_u= sorted(device_numbers_u)\n",
    "upload_df[\"hour\"]=pd.to_numeric(upload_df[\"time\"].dt.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_subset_u=coordinates_df[coordinates_df[\"device_number\"].isin(device_numbers_u)]\n",
    "#coordinates_subset_u=coordinates_subset_u[np.isfinite(coordinates_subset_u['Up'])]\n",
    "coordinates_subset_u=coordinates_subset_u.sort_values(by=\"device_number\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_line=go.Scatter(x=coordinates_subset_u[\"device_number\"],\n",
    "#                  y=coordinates_subset_u[\"Up\"], mode='markers',marker=dict(color='blue'), name='Bandwidth bought')\n",
    "\n",
    "t=\"Bandwidth bought and upload speeds\"+title_tail\n",
    "simple_boxplot(dataframe=upload_df,plot_value='UPLOAD',sort_value='SK_PI',\n",
    "               title=t, \n",
    "               ytitle=\"Upload speed (Mbps)\",\n",
    "               xtitle=\"Device number\",uploadline=True)#, boughtline=b_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. iPerf data\n",
    "\n",
    "The speedtest devices use a number of testing platforms to gather data. In addition to using the speedtest.net platform, [iPerf](https://iperf.fr/) is also being used. Initial observations from this data exploration are shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of data points, reporting times for the iPerf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting_point=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "starting_point=\"2019-02-07 14:00:00\"  # to set upl alternative starting point\n",
    "#print(\"Starting point:\",starting_point )\n",
    "\n",
    "title_tail=\" to the date \"+ starting_point\n",
    "\n",
    "time_interval='4w' #5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_numbers=get_tag_values_influxdb(client_influx=client,table_name='SPEEDTEST_IPERF_DOWNLOAD', tag_name='SK_PI')\n",
    "device_numbers=list(map(int, device_numbers))\n",
    "device_numbers= sorted(device_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_download_counts = \"SELECT COUNT(DOWNLOAD) FROM SPEEDTEST_IPERF_DOWNLOAD WHERE PROVIDER='iperf' AND time<= '\"+starting_point+\"' AND DOWNLOAD>0 GROUP BY SK_PI;\"\n",
    "download_counts=get_stats_influxdb(client_influx=client,\n",
    "                               query_influx=query_download_counts,\n",
    "                               stat_name='count',\n",
    "                               device_numbers=device_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_bar_plot(xvalues=device_numbers,\n",
    "                yvalues=download_counts,\n",
    "                name=\"ping datapoints\",\n",
    "                title=\"Number of data points per device(Iperf) \"+ title_tail,\n",
    "                ytitle=\"Number of datapoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows number of datapoints collected by the `iPerf` test until today (meeting date 2019-02-07 14:00). Tests are scheduled to occur approximately every 4 hours. As such, we would expect to see far larger numbers for number of tests collected over several months (would expect ~180/month). As such, it appears the devices were not collected iPerf data as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_upload_last = \"SELECT LAST(UPLOAD), time FROM SPEEDTEST_IPERF_UPLOAD WHERE PROVIDER='iperf' AND time <= '\"+starting_point+\"' AND UPLOAD>0 GROUP BY SK_PI;\"\n",
    "result_upload_last=get_stats_influxdb(client_influx=client,\n",
    "                               query_influx=query_upload_last,\n",
    "                               stat_name='time',\n",
    "                               device_numbers=device_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_upload_first = \"SELECT FIRST(UPLOAD), time FROM SPEEDTEST_IPERF_UPLOAD WHERE PROVIDER='iperf' AND time <= '\"+starting_point+\"' AND UPLOAD>0 GROUP BY SK_PI;\"\n",
    "result_upload_first=get_stats_influxdb(client_influx=client,\n",
    "                               query_influx=query_upload_first,\n",
    "                               stat_name='time',\n",
    "                               device_numbers=device_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(len(device_numbers)):\n",
    "    try:\n",
    "        result_upload_first[i] = dateutil.parser.parse(result_upload_first[i]).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        result_upload_first[i]=None\n",
    "    try:    \n",
    "        result_upload_last[i] = dateutil.parser.parse(result_upload_last[i]).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        result_upload_last[i]=None\n",
    "    #print(\"Device: \", device_numbers[i],\"  was reporting from \", result_upload_first[i], \" to \",result_upload_last[i])\n",
    "    trace = go.Scatter(x=[result_upload_first[i],result_upload_last[i]],y=[device_numbers[i],device_numbers[i]], \n",
    "                       name = device_numbers[i],marker=dict(color=colors[i]))\n",
    "    data.append(trace)\n",
    "layout = dict(title = \"Device reporting times (iPerf) \"+ title_tail,xaxis=dict(title=\"Time\"),\n",
    "        yaxis=dict(title=\"Device Number\"))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like all devices stopped reporting iPerf data at approximately the same time (December 3), suggesting there might be an issue with the test server itself. \n",
    "\n",
    "We are able to ping/reach `clearskystatus.info` but all iPerf tests are failing:\n",
    "   >/usr/bin/iperf3 -c clearskystatus.info  \n",
    "   >iperf3: error - unable to connect to server: Operation timed out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the same in grafana (screenshot below), all devices stopped reporting `iperf` data on Dec 3rd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/grafana-iperf1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing  iperf and speedtest data\n",
    "Since `iperf` stopped reporting on Dec 3rd, we will only select all data collected before Dec 4th for both sources `speedtest` and `iperf` in order to compare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up starting point, by default if will start from current time\n",
    "#starting_point=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "starting_point=\"2018-12-04 00:00:00\"  # to set upl alternative starting point\n",
    "print(\"Starting point:\",starting_point )\n",
    "\n",
    "title_tail=\" to the date \"+ starting_point\n",
    "query_tail=\" AND time < '\"+starting_point+\"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_download1 = \"SELECT * FROM SPEEDTEST_IPERF_DOWNLOAD WHERE PROVIDER!='iperf' AND DOWNLOAD>0\"+ query_tail+\";\"\n",
    "download_df1 = get_dataframe_from_influxdb(client_df=client_df,query_influx=query_download1,table_name='SPEEDTEST_IPERF_DOWNLOAD')\n",
    "device_numbers_d1=download_df1['SK_PI'].unique()\n",
    "device_numbers_d1=list(map(int, device_numbers_d1))\n",
    "device_numbers_d1= sorted(device_numbers_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_download2 = \"SELECT * FROM SPEEDTEST_IPERF_DOWNLOAD WHERE PROVIDER='iperf' AND DOWNLOAD>0\"+ query_tail+\";\"\n",
    "download_df2 = get_dataframe_from_influxdb(client_df=client_df,query_influx=query_download2,table_name='SPEEDTEST_IPERF_DOWNLOAD')\n",
    "download_df2['DOWNLOAD']=download_df2['DOWNLOAD']*0.001\n",
    "device_numbers_d2=download_df2['SK_PI'].unique()\n",
    "device_numbers_d2=list(map(int, device_numbers_d2))\n",
    "device_numbers_d2= sorted(device_numbers_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=pd.DataFrame(download_df1.groupby('SK_PI').size())\n",
    "result1.columns=['size1']\n",
    "\n",
    "result2=pd.DataFrame(download_df2.groupby('SK_PI').size())\n",
    "result2.columns=['size2']\n",
    "result=result2.join(result1,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_bar_plot_2traces(xvalues=result.index.astype(int),\n",
    "                          yvalues1=result['size1'],\n",
    "                          yvalues2=result['size2'],\n",
    "                          name1='speedtest',\n",
    "                          name2='iperf',\n",
    "                          title=\"Comparing number of datapoints for speedtest and iperf\"+title_tail ,\n",
    "                          ytitle=\"Number of datapoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows how many datapoints were collected by `speedtest` and `iperf` up to December 4th. Both tests are set up to run every 3hrs 42 mins, but looking at the graph the numbers are slightly different: less data was collected by `iperf`. \n",
    "\n",
    "The Grafana screenshot below shows that the `iperf` test (shown in yellow) was not run as consistently as the `speedtest` tests (green). This is seen by the presence of gaps in data. \n",
    "(Note that we are looking at ping latency below in order to get an indication for test frequency, as Download/Upload speeds are collected in different units by `speedtest` and `iperf` and more difficult to visualy compare in Grafana)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/grafana-speedtest1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"Download speed by device for speedtest vs iperf data\"+title_tail\n",
    "scatterplot_2groups(title=t,dataframe1=download_df1,dataframe2=download_df2,\n",
    "                    plot_value=\"DOWNLOAD\",ytitle=\"Download speed (Mbps)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Download speeds by device, we can see that the `iperf` data is consistently lower than the `speedtest` data. Let's take a closer look at Mean/Median chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11=pd.DataFrame(download_df1.groupby('SK_PI')['DOWNLOAD'].mean())\n",
    "result11.columns=['mean1']\n",
    "result12=pd.DataFrame(download_df1.groupby('SK_PI')['DOWNLOAD'].median())\n",
    "result12.columns=['median1']\n",
    "result1=result11.join(result12,how='outer')\n",
    "\n",
    "result21=pd.DataFrame(download_df2.groupby('SK_PI')['DOWNLOAD'].mean())\n",
    "result21.columns=['mean2']\n",
    "result22=pd.DataFrame(download_df2.groupby('SK_PI')['DOWNLOAD'].median())\n",
    "result22.columns=['median2']\n",
    "result2=result21.join(result22,how='outer')\n",
    "\n",
    "result=result2.join(result1,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_numbers_d=result.index\n",
    "download_line=go.Scatter(x=device_numbers_d,y=[50] * len(device_numbers_d), mode='markers',marker=dict(color='red'), name='50Mbps')\n",
    "\n",
    "combined_bar_plot_4traces(xvalues=result.index,\n",
    "                         yvalues1=result[\"mean1\"],\n",
    "                         yvalues2=result[\"mean2\"],\n",
    "                         yvalues3=result[\"median1\"],\n",
    "                         yvalues4=result[\"median2\"],\n",
    "                         name1=\"Mean speedtest\",\n",
    "                         name2=\"Mean iperf\",\n",
    "                         name3=\"Median speedtest\",\n",
    "                         name4=\"Median iperf\",\n",
    "                         title=\"Download speed by device\" +title_tail,\n",
    "                         ytitle=\"Mbps\",\n",
    "                         line=download_line,\n",
    "                         stack=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it's interesting to see that for devices 1, 2, 4, 5, 12  the data from both sources looks similar.\n",
    "But for devices 3, 8, 7 and 11 the `speedtest` and `iperf` speeds are very different (speedtest has much better results). Device #3 is our control device located in Calgary, so its trying to use test server in Manitoba and shows worse results. The location of devices 8 and 9 is not known. Device 11 is in Ginew, Manitoba.\n",
    "\n",
    "In the plot below, the same trend is seen in that the `iperf` data is concentrated at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_upload1 = \"SELECT * FROM SPEEDTEST_IPERF_UPLOAD WHERE PROVIDER!='iperf' AND UPLOAD>0\"+ query_tail+\";\"\n",
    "upload_df1 = get_dataframe_from_influxdb(client_df=client_df,query_influx=query_upload1,table_name='SPEEDTEST_IPERF_UPLOAD')\n",
    "device_numbers_u1=upload_df1['SK_PI'].unique()\n",
    "device_numbers_u1=list(map(int, device_numbers_u1))\n",
    "device_numbers_u1= sorted(device_numbers_u1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_upload2 = \"SELECT * FROM SPEEDTEST_IPERF_UPLOAD WHERE PROVIDER='iperf' AND UPLOAD>0\"+ query_tail+\";\"\n",
    "upload_df2 = get_dataframe_from_influxdb(client_df=client_df,query_influx=query_upload2,table_name='SPEEDTEST_IPERF_UPLOAD')\n",
    "upload_df2['UPLOAD']=upload_df2['UPLOAD']*0.001\n",
    "device_numbers_u2=download_df2['SK_PI'].unique()\n",
    "device_numbers_u2=list(map(int, device_numbers_u2))\n",
    "device_numbers_u2= sorted(device_numbers_u2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"Upload speed by device for speedtest vs iperf data\"+title_tail\n",
    "scatterplot_2groups(title=t,dataframe1=upload_df1,dataframe2=upload_df2,\n",
    "                    plot_value=\"UPLOAD\",ytitle=\"Upload speed (Mbps)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11=pd.DataFrame(upload_df1.groupby('SK_PI')['UPLOAD'].mean())\n",
    "result11.columns=['mean1']\n",
    "result12=pd.DataFrame(upload_df1.groupby('SK_PI')['UPLOAD'].median())\n",
    "result12.columns=['median1']\n",
    "result1=result11.join(result12,how='outer')\n",
    "\n",
    "result21=pd.DataFrame(upload_df2.groupby('SK_PI')['UPLOAD'].mean())\n",
    "result21.columns=['mean2']\n",
    "result22=pd.DataFrame(upload_df2.groupby('SK_PI')['UPLOAD'].median())\n",
    "result22.columns=['median2']\n",
    "result2=result21.join(result22,how='outer')\n",
    "\n",
    "result=result2.join(result1,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_numbers_u=result.index\n",
    "upload_line=go.Scatter(x=device_numbers_d,y=[10] * len(device_numbers_u), mode='markers',marker=dict(color='red'), name='10Mbps')\n",
    "\n",
    "combined_bar_plot_4traces(xvalues=result.index,\n",
    "                         yvalues1=result[\"mean1\"],\n",
    "                         yvalues2=result[\"mean2\"],\n",
    "                         yvalues3=result[\"median1\"],\n",
    "                         yvalues4=result[\"median2\"],\n",
    "                         name1=\"Mean speedtest\",\n",
    "                         name2=\"Mean iperf\",\n",
    "                         name3=\"Median speedtest\",\n",
    "                         name4=\"Median iperf\",\n",
    "                         title=\"Upload speed by device\" +title_tail,\n",
    "                         ytitle=\"Mbps\",\n",
    "                         line=upload_line,\n",
    "                         stack=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this chart with the same  for Download speed we can see that more devices having worse results for iperf test. It looks fairly similar for devices 1, 2, 4 and 5, for the rest of the devices the speeds are quite different between `iperf`  and `speedtest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df1[\"hour\"]=pd.to_numeric(upload_df1[\"time\"].dt.hour)\n",
    "upload_df2[\"hour\"]=pd.to_numeric(upload_df2[\"time\"].dt.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_number=7\n",
    "subset1=upload_df1[upload_df1[\"SK_PI\"]==device_number]\n",
    "subset2=upload_df2[upload_df2[\"SK_PI\"]==device_number]\n",
    "boxplot_2groups(dataframe1=subset1,dataframe2=subset2,plot_value='UPLOAD',sort_value='hour',\n",
    "               title=\"Upload speed by hour for device: \"+str(device_number)+\" (orange - speedtest, purple - iperf)\"+title_tail,\n",
    "               ytitle=\"Mbps\", xtitle=\"Hour of the day\", uploadline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the upload speed by hour of the day for device #7. We used a similar plot in last meeting's report (Jan 24, 2019) to demonstrated that this device reaches CRTC target (10Mbps) for upload speed only at night/early morning with `speedtest` data.  \n",
    "\n",
    "Now we have added data coming from `iperf` (purple) as well and we can see the same trend - speeds are going up between 2 to 5 am and then going down during business hours. But at the same time according to the `iperf` data this device never reaches CRTC target of 10Mbps.  \n",
    "\n",
    "The same trend can be seen in the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df1[\"time_group\"]=\"\"\n",
    "upload_df1.loc[(upload_df1[\"hour\"]>23)|(upload_df1[\"hour\"]<=7),\"time_group\"]=\"night 23:00-07:00\"\n",
    "upload_df1.loc[(upload_df1[\"hour\"]>7)&(upload_df1[\"hour\"]<=17),\"time_group\"]=\"day 7:00-17:00\"\n",
    "upload_df1.loc[(upload_df1[\"hour\"]>17)&(upload_df1[\"hour\"]<=23),\"time_group\"]=\"evening 17:00-23:00\"\n",
    "upload_df2[\"time_group\"]=\"\"\n",
    "upload_df2.loc[(upload_df2[\"hour\"]>23)|(upload_df2[\"hour\"]<=7),\"time_group\"]=\"night 23:00-07:00\"\n",
    "upload_df2.loc[(upload_df2[\"hour\"]>7)&(upload_df2[\"hour\"]<=17),\"time_group\"]=\"day 7:00-17:00\"\n",
    "upload_df2.loc[(upload_df2[\"hour\"]>17)&(upload_df2[\"hour\"]<=23),\"time_group\"]=\"evening 17:00-23:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_number=7\n",
    "subset1=upload_df1[upload_df1[\"SK_PI\"]==device_number]\n",
    "subset2=upload_df2[upload_df2[\"SK_PI\"]==device_number]\n",
    "boxplot_2groups(dataframe1=subset1,dataframe2=subset2,plot_value='UPLOAD',sort_value='time_group',\n",
    "               title=\"Upload speed by time of the day for device: \"+str(device_number)+\" (orange - speedtest, purple - iperf)\"+title_tail,\n",
    "               ytitle=\"Mbps\", xtitle=\"\", uploadline=True, jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ping1 = \"SELECT * FROM SPEEDTEST_IPERF_PING WHERE PROVIDER!='iperf' AND PING>0\"+ query_tail+\";\"\n",
    "ping_df1 = get_dataframe_from_influxdb(client_df=client_df,query_influx=query_ping1,table_name='SPEEDTEST_IPERF_PING')\n",
    "device_numbers_p1=ping_df1['SK_PI'].unique()\n",
    "device_numbers_p1=list(map(int, device_numbers_p1))\n",
    "device_numbers_p1= sorted(device_numbers_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ping2 = \"SELECT * FROM SPEEDTEST_IPERF_PING WHERE PROVIDER='iperf' AND PING>0\"+ query_tail+\";\"\n",
    "ping_df2 = get_dataframe_from_influxdb(client_df=client_df,query_influx=query_ping2,table_name='SPEEDTEST_IPERF_PING')\n",
    "device_numbers_p2=ping_df2['SK_PI'].unique()\n",
    "device_numbers_p2=list(map(int, device_numbers_p2))\n",
    "device_numbers_p2= sorted(device_numbers_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"Ping latency by device for speedtest vs iperf data\"+title_tail\n",
    "scatterplot_2groups(title=t,dataframe1=ping_df1,dataframe2=ping_df2,\n",
    "                    plot_value=\"PING\",ytitle=\"Ping latency(Miliseconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing ping latency from the two platforms we see that iPerf reports lower latencies than speetest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11=pd.DataFrame(ping_df1.groupby('SK_PI')['PING'].mean())\n",
    "result11.columns=['mean1']\n",
    "result12=pd.DataFrame(ping_df1.groupby('SK_PI')['PING'].median())\n",
    "result12.columns=['median1']\n",
    "result1=result11.join(result12,how='outer')\n",
    "\n",
    "result21=pd.DataFrame(ping_df2.groupby('SK_PI')['PING'].mean())\n",
    "result21.columns=['mean2']\n",
    "result22=pd.DataFrame(ping_df2.groupby('SK_PI')['PING'].median())\n",
    "result22.columns=['median2']\n",
    "result2=result21.join(result22,how='outer')\n",
    "\n",
    "result=result2.join(result1,how='outer')\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_bar_plot_4traces(xvalues=result.index,\n",
    "                         yvalues1=result[\"mean1\"],\n",
    "                         yvalues2=result[\"mean2\"],\n",
    "                         yvalues3=result[\"median1\"],\n",
    "                         yvalues4=result[\"median2\"],\n",
    "                         name1=\"Mean speedtest\",\n",
    "                         name2=\"Mean iperf\",\n",
    "                         name3=\"Median speedtest\",\n",
    "                         name4=\"Median iperf\",\n",
    "                         title=\"Ping latency by device\" +title_tail,\n",
    "                         ytitle=\"Miliseconds\",\n",
    "                         stack=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows that for almost all of the devices (except for #3 (Calgary control device) and #8 (location unknown)), median and average ping latencies coming from `iperf` are better than latencies coming from `speedtest`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical comparison of download speeds \n",
    "\n",
    "In order to evaluate if a device reaches the CRTC target of 50Mbps, we tried to calculate percentage of datapoints below and above the threshold in the last investigation (Jan 24th). This time we will try to apply more formal, statistical approach. \n",
    "\n",
    "We will apply normality tests, resmapling and t-tests on download speed data. The same way it can be applied to upload speed data and ping latency. \n",
    "\n",
    "We will take all the data we have in speedtest database as of this date (meeting date 2019-02-07 14:00) and keep only devices with a minimum 100 datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect all data?\n",
    "all_data=False\n",
    "\n",
    "#Set up test time interval:\n",
    "#time_interval='4w' #2w\n",
    "\n",
    "#Set up starting point, by default if will start from current time\n",
    "#starting_point=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "starting_point=\"2019-02-07 14:00:00\"  # to set upl alternative starting point\n",
    "\n",
    "title_tail=\"\"\n",
    "query_tail=\"\"\n",
    "\n",
    "if not all_data:\n",
    "    ##tail to all the titles\n",
    "    title_tail=\" to the date \"+ starting_point\n",
    "    ##tail for all the influxdb queries\n",
    "    query_tail=\" AND time <= '\"+starting_point+\"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_data:#Set up test time interval:\n",
    "    print(\"Selecting all data(speedtest) from the database back from starting point:\",starting_point )\n",
    "else:\n",
    "    print(\"Selecting all data(speedtest) from the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size=100\n",
    "print(\"Minimum sample size:\",min_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_download = \"SELECT * FROM SPEEDTEST_IPERF_DOWNLOAD WHERE PROVIDER!='iperf' AND DOWNLOAD>0\"+ query_tail+\";\"\n",
    "download_df = get_dataframe_from_influxdb(client_df=client_df,query_influx=query_download,table_name='SPEEDTEST_IPERF_DOWNLOAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame(download_df.groupby('SK_PI').size())\n",
    "result.columns=['size']\n",
    "tobe_excluded=result[result['size']<=min_sample_size].index\n",
    "download_df=download_df[~download_df['SK_PI'].isin(tobe_excluded)]\n",
    "device_numbers_d=download_df['SK_PI'].unique()\n",
    "device_numbers_d=list(map(int, device_numbers_d))\n",
    "device_numbers_d= sorted(device_numbers_d)\n",
    "print(\"Devices that are going to be tested:\",device_numbers_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if data is normally distributed:\n",
    "The first step we need to perform is to test if the data is [normally distributed](https://www.varsitytutors.com/hotmath/hotmath_help/topics/normal-distribution-of-data). This will impact the method we can choose for the statistical testing.  \n",
    "\n",
    "To find out if data is normally distributed or not we will perform visual tests (distribution plots) and statistical tests (Kolmogorov-Smirnov)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t='Distribution plots for download speed per device'+title_tail\n",
    "dist_subplots(dataframe=download_df,plot_value='DOWNLOAD',device_numbers=device_numbers_d, title=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection shows that possibly devices #14 and #10 roughly take on the shape of a bell curve.\n",
    "Let's compare with Kolmogorov-Smirnov test, which numerically tests for normally distributed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "matrix_sw = []\n",
    "for device in device_numbers_d:\n",
    "    subset=download_df[download_df[\"SK_PI\"]==device]\n",
    "    shapiro_results =scipy.stats.shapiro(subset['DOWNLOAD'])\n",
    "    ks_results = scipy.stats.kstest(subset['DOWNLOAD'], cdf='norm',args=(subset['DOWNLOAD'].mean(), subset['DOWNLOAD'].std()))\n",
    "    dagostino_results = scipy.stats.normaltest(subset['DOWNLOAD'])\n",
    "    matrix_sw.append(\n",
    "    [device, len(subset['DOWNLOAD']) - 1, shapiro_results[0], shapiro_results[1], ks_results[0], ks_results[1],\n",
    "    dagostino_results[0], dagostino_results[1]])\n",
    "\n",
    "df = pd.DataFrame(matrix_sw)\n",
    "\n",
    "df.columns=['Device number', 'Degrees of freedom', 'Shapiro-Wilk Test Statistic', 'Shapiro-Wilk p-value',\n",
    "     'Kolmogorov-Smirnov test Statistic','Kolmogorov-Smirnov p-value',\n",
    "     \"D'Agostino's K-squared test Statistic\",\"D'Agostino's K-squared p-value\" ]\n",
    "\n",
    "df=df.reset_index().set_index(\"Device number\")\n",
    "df.drop(['index'], axis=1, inplace=True)\n",
    "df[\"Shapiro-Wilk\"]='n'\n",
    "df.loc[(df[\"Shapiro-Wilk p-value\"]>alpha),\"Shapiro-Wilk\"]='y'\n",
    "df[\"Kolmogorov-Smirnov\"]='n'\n",
    "df.loc[(df[\"Kolmogorov-Smirnov p-value\"]>alpha),\"Kolmogorov-Smirnov\"]='y'\n",
    "df[\"D'Agostino's K-squared\"]='n'\n",
    "df.loc[(df[\"D'Agostino's K-squared p-value\"]>alpha),\"D'Agostino's K-squared\"]='y'\n",
    "\n",
    "result=df[[\"Shapiro-Wilk\",\"Kolmogorov-Smirnov\",\"D'Agostino's K-squared\"]]\n",
    "result_table = ff.create_table(result, index=True)\n",
    "#iplot(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normally_distributed_d=list(result[result[\"Kolmogorov-Smirnov\"]=='y'].index)\n",
    "not_normally_distributed_d=list(result[result[\"Kolmogorov-Smirnov\"]=='n'].index)\n",
    "print(\"Normally distributed devices according to the Kolmogorov-Smirnov test: \",normally_distributed_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if the mean of the population of normally distributed data is statistically different from the threshold of 50Mbps:\n",
    "\n",
    "Now we can run a [t-test](https://researchbasics.education.uconn.edu/t-test/) for normally distributed data.\n",
    "\n",
    "A t-test is commonly used to determine whether the mean of a population significantly differs from a specific value (called the hypothesized mean) or from the mean of another population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For normally distributed devices  - how far are they from the treshold of 50Mbps?   \n",
    "# **H0** - null hypothesis - mean is = 50 (less than 50)  \n",
    "# **Ha** - altenative hypothesis -mean is greater than 50  \n",
    "\n",
    "# Confidence interval 95%\n",
    "\n",
    "# **1-tailed 1-sample t-test**:  \n",
    "# p/2 <= alpha: reject H0    \n",
    "# t-statistics> 0 and p/2 > alpha: fail to reject H0, mean is greater than 50  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mean = 50\n",
    "alpha = 0.05\n",
    "list_t = []\n",
    "for device in normally_distributed_d:\n",
    "#for device in device_numbers_d:\n",
    "    subset=download_df[download_df[\"SK_PI\"]==device]\n",
    "    onesample_results = scipy.stats.ttest_1samp(subset[\"DOWNLOAD\"], true_mean)\n",
    "    list_t.append(\n",
    "    [device, round(subset[\"DOWNLOAD\"].mean(),2), round(subset[\"DOWNLOAD\"].std(),2), round(onesample_results[0],2), onesample_results[1]/2])\n",
    "\n",
    "df1 = pd.DataFrame(list_t)\n",
    "\n",
    "df1.columns=['Device number',\"Mean\",\"Standart deviation\",\"t-statistics\",\"p-value/2\"]\n",
    "df1=df1.reset_index().set_index(\"Device number\")\n",
    "df1 = df1.drop('index', 1)\n",
    "df1[\"Statistically > 50Mbps\"]='n'\n",
    "df1.loc[(df1[\"t-statistics\"]>0) & (df1[\"p-value/2\"]< alpha),\"Statistically > 50Mbps\"]='y'\n",
    "df1=df1[[\"Mean\",\"Statistically > 50Mbps\"]]\n",
    "result_table = ff.create_table(df1, index=True)\n",
    "iplot(result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test results show that for the 3 devices with normally distributed data, if the data will be collected in the same way the mean of the entire population is not higher than 50Mbps at a 95% confidence level (based on the sample of data we collected so far).  \n",
    "\n",
    "Visual inspection of the curerent data supports this conclusion: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"Download speed by device \"+title_tail\n",
    "#simple_boxplot(dataframe=download_df,plot_value='DOWNLOAD',sort_value='SK_PI',\n",
    "simple_boxplot(dataframe=download_df[download_df[\"SK_PI\"].isin(normally_distributed_d)],plot_value='DOWNLOAD',sort_value='SK_PI',\n",
    "               title=t, \n",
    "               ytitle=\"Download speed (Mbps)\",\n",
    "               xtitle=\"Device number\", downloadline=True, jitter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Devices with data not normally distributed: \",not_normally_distributed_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we statistically evaluate the data that is not normally distributed? Following the same methodology used by [SamKnows](https://availability.samknows.com/broadband/uploads/methodology/SamKnows_Sample_Size_Whitepaper_20150610.pdf), we can apply resampling and use the Central Limit Theorem:\n",
    "\n",
    ">If the download speed distribution is not normal, the mean has an unknown\n",
    ">distribution and strictly speaking the t-test is inapplicable. However according to\n",
    ">the central limit theorem, as the sample size increases, the distribution of the\n",
    ">mean tends to be normal. Therefore if the sample size is big enough, the t-test\n",
    ">and confidence interval are valid even if the download speed is not from a normal\n",
    ">distribution.\n",
    "\n",
    "We will create 500 samples with replacement with 45 values each and calculate the mean for every sample. SamKnows recommends using 1000 samples (sample size 45)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_r=45\n",
    "num_samples_r=500\n",
    "matrix_r=[]\n",
    "for device in not_normally_distributed_d:\n",
    "    list_r=[]\n",
    "    subset=download_df[download_df[\"SK_PI\"]==device]\n",
    "    for i in range(num_samples_r):\n",
    "        sample = resample(subset[\"DOWNLOAD\"], replace=True, n_samples=sample_size_r, random_state=i)\n",
    "        list_r.append(sample.mean())\n",
    "    matrix_r.append([device]+list_r)\n",
    "    \n",
    "df_r = pd.DataFrame(matrix_r)\n",
    "df_r=df_r.transpose()\n",
    "df_r.columns = df_r.iloc[0]\n",
    "df_r=df_r.reindex(df_r.index.drop(0))\n",
    "#df_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "matrix_sw = []\n",
    "for device in not_normally_distributed_d:\n",
    "    subset=df_r[device]\n",
    "    shapiro_results =scipy.stats.shapiro(subset)\n",
    "    ks_results = scipy.stats.kstest(subset, cdf='norm',args=(subset.mean(), subset.std()))\n",
    "    dagostino_results = scipy.stats.normaltest(subset)\n",
    "    matrix_sw.append(\n",
    "    [device, len(subset) - 1, shapiro_results[0], shapiro_results[1], ks_results[0], ks_results[1],\n",
    "     dagostino_results[0], dagostino_results[1]])\n",
    "\n",
    "df = pd.DataFrame(matrix_sw)\n",
    "\n",
    "df.columns=['Device number', 'Degrees of freedom', 'Shapiro-Wilk Test Statistic', 'Shapiro-Wilk p-value',\n",
    "     'Kolmogorov-Smirnov test Statistic','Kolmogorov-Smirnov p-value',\n",
    "     \"D'Agostino's K-squared test Statistic\",\"D'Agostino's K-squared p-value\" ]\n",
    "\n",
    "df=df.reset_index().set_index(\"Device number\")\n",
    "df.drop(['index'], axis=1, inplace=True)\n",
    "df[\"Shapiro-Wilk\"]='n'\n",
    "df.loc[(df[\"Shapiro-Wilk p-value\"]>alpha),\"Shapiro-Wilk\"]='y'\n",
    "df[\"Kolmogorov-Smirnov\"]='n'\n",
    "df.loc[(df[\"Kolmogorov-Smirnov p-value\"]>alpha),\"Kolmogorov-Smirnov\"]='y'\n",
    "df[\"D'Agostino's K-squared\"]='n'\n",
    "df.loc[(df[\"D'Agostino's K-squared p-value\"]>alpha),\"D'Agostino's K-squared\"]='y'\n",
    "\n",
    "result=df[[\"Shapiro-Wilk\",\"Kolmogorov-Smirnov\",\"D'Agostino's K-squared\"]]\n",
    "result_table = ff.create_table(result, index=True)\n",
    "#iplot(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normally_distributed_d1=list(result[result[\"Kolmogorov-Smirnov\"]=='y'].index)\n",
    "#print(\"Normally distributed devices according to the Kolmogorov-Smirnov test: \",normally_distributed_d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have applied this method we transformed data from almost all the devices to \"normal\"  and can apply t-test the same was we applied it before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mean = 50\n",
    "alpha = 0.05\n",
    "list_t = []\n",
    "for device in normally_distributed_d1:\n",
    "    subset=df_r[device]\n",
    "    onesample_results = scipy.stats.ttest_1samp(subset, true_mean)\n",
    "    list_t.append(\n",
    "    [device, round(subset.mean(),2), round(subset.std(),2), round(onesample_results[0],2), onesample_results[1]/2])\n",
    "\n",
    "df2 = pd.DataFrame(list_t)\n",
    "\n",
    "df2.columns=['Device number',\"Mean\",\"Standart deviation\",\"t-statistics\",\"p-value/2\"]\n",
    "df2=df2.reset_index().set_index(\"Device number\")\n",
    "df2 = df2.drop('index', 1)\n",
    "df2[\"Statistically > 50Mbps\"]='n'\n",
    "df2.loc[(df2[\"t-statistics\"]>0) & (df2[\"p-value/2\"]< alpha),\"Statistically > 50Mbps\"]='y'\n",
    "df2=df2[[\"Mean\",\"Statistically > 50Mbps\"]]\n",
    "result_table = ff.create_table(df2, index=True)\n",
    "iplot(result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the t-test results devices 5, 7, 9, 11, 12, 16, 17, 18, show means significantly lower than 50 Mbps at a 95% confidence level (based on the sample of data we collected so far).  \n",
    "\n",
    "\n",
    "Devices 3 and 14 show statistically significantly higher speeds than 50 Mbps (current means are 172 Mbps and 92 Mbps, respectively).  \n",
    "We can visually inspect this with our current sample of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"Download speed by device \"+title_tail\n",
    "#simple_boxplot(dataframe=download_df,plot_value='DOWNLOAD',sort_value='SK_PI',\n",
    "simple_boxplot(dataframe=download_df[download_df[\"SK_PI\"].isin(not_normally_distributed_d)],plot_value='DOWNLOAD',sort_value='SK_PI',\n",
    "               title=t, \n",
    "               ytitle=\"Download speed (Mbps)\",\n",
    "               xtitle=\"Device number\", downloadline=True, jitter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For device 14, part of the data is below 50 Mbps and part of the data is above. Based on our statistical evaluation, the mean of the population is above 50 Mbps. However, in the context of CRTC's standards, we are not certain whether this means that the device is in a \"served\" or \"underserved\" area. This raises further questions about how the CRTC defines \"served\" and \"underserved\" areas. For example, do the reference speeds of 50 Mbps and 10 Mbps refer to means or medians? Do these speeds have to be met 90% of the time? 10% of the time? Many interpretations of the minimum speeds are possible and there is no clear definition available from the CRTC at this time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For next steps, we will focus on automating the analysis presented over the last few weeks and specifically, making it broadly applicable beyond the devices that we have data for at this time. We will also try to find out from the CRTC the definition of \"underserved\" region."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
